# AI-Knowledge-Base
ğŸ“š AI Knowledge Base

A full-stack Retrieval-Augmented Generation (RAG) application that lets users upload PDFs/TXT files and query them in natural language. The system retrieves relevant context and generates grounded answers with cited sources using Ollama LLMs (Mistral).

âœ¨ Features

ğŸ” Semantic Search â€” Uses FAISS + Sentence Transformers to embed and retrieve the most relevant text chunks.

ğŸ¤– LLM Integration â€” Contextual prompting pipeline with Ollama (Mistral) for concise, grounded answers.

ğŸ“‚ File Uploads â€” Users can upload .pdf or .txt documents for indexing and querying.

ğŸ–¥ï¸ Full-Stack Implementation

Backend: FastAPI with endpoints for file processing, embeddings indexing, and Q&A.

Frontend: Next.js + Tailwind for a clean, interactive UI.

ğŸ“‘ Transparent Responses â€” Answers include source text snippets for credibility.

ğŸ›  Tech Stack

Backend: FastAPI, FAISS, Sentence Transformers, Ollama

Frontend: Next.js, React, Tailwind CSS, Axios

Other: PDF/Text parsing, CORS-enabled API

ğŸš€ How It Works

Upload a .pdf or .txt file.

The backend extracts content, splits it into chunks, and indexes embeddings with FAISS.

Ask a question in natural language.

The app retrieves the top-k relevant chunks and passes them to Ollama for answer generation.

The UI displays the answer with cited sources.
